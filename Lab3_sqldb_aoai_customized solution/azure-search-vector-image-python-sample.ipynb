{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search Vector Search Code Sample with Azure AI Vision Image Retreival API for Images\n",
    "This code demonstrates how to use Azure AI Search with Azure AI Vision Image Retreival API and Azure Python SDK\n",
    "## Prerequisites\n",
    "To run the code, install the following packages. Please use the latest stable version by running `pip install azure-search-documents`. This sample currently uses version `11.4.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (11.4.0b11)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from azure-search-documents) (1.29.7)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-search-documents) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2023.7.22)\n",
      "Requirement already satisfied: openai in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (8.16.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (5.11.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nicolepham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nicolepham\\appdata\\roaming\\python\\python39\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents \n",
    "#pip install azure-search-documents --pre --upgrade\n",
    "! pip install openai python-dotenv ipython \n",
    "! pip install azure-search --pre --upgrade\n",
    "! pip install azure-core --pre --upgrade\n",
    "! pip install azure-storage-blob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import requests  \n",
    "from dotenv import load_dotenv  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.search.documents.indexes.models import (  \n",
    " \n",
    "    ExhaustiveKnnParameters,  \n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    FieldMapping,  \n",
    "    HnswParameters,  \n",
    "    HnswAlgorithmConfiguration,  \n",
    "    InputFieldMappingEntry,  \n",
    "    OutputFieldMappingEntry,  \n",
    "    SimpleField,\n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SearchIndex,  \n",
    "    SearchIndexer,  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexerDataSourceConnection,  \n",
    "    SearchIndexerSkillset,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmKind,  \n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,  \n",
    "    WebApiSkill\n",
    ")  \n",
    "from IPython.display import Image, display \n",
    "from azure.storage.blob import BlobServiceClient  \n",
    "\n",
    "  \n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "aiVisionEndpoint = os.getenv(\"AZURE_AI_VISION_ENDPOINT\")  \n",
    "aiVisionApiKey = os.getenv(\"AZURE_AI_VISION_API_KEY\")  \n",
    "customSkill_endpoint = os.getenv(\"FUNCTION_CUSTOM_SKILL_ENDPOINT\")  \n",
    "blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
    "container_name = os.getenv(\"BLOB_CONTAINER_NAME\")\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Blob Storage\n",
    "\n",
    "Retreive your images from Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL of the first blob: https://storageacctestunp.blob.core.windows.net/images/68747470733a2f2f6673756e6176616c6173746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f766563746f722d73616e64626f782f506963747572653238352e6a7067.jpg\n"
     ]
    }
   ],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "\n",
    "first_blob = next(blobs)\n",
    "blob_url = container_client.get_blob_client(first_blob).url\n",
    "print(f\"URL of the first blob: {blob_url}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect your Blob Storage to a data source in Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'imagesearch-index-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "# Create a data source \n",
    "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a skillset\n",
    "\n",
    "Create a custom skill Azure Function which calls the Florence Vision API to generate image embeddings. See GetImageEmbeddings for details on the custom skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " imagesearch-index-skillset created\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "skill_uri = customSkill_endpoint\n",
    "  \n",
    "skill = WebApiSkill(  \n",
    "    uri=skill_uri,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"imageUrl\", source=\"/document/metadata_storage_path\"),  \n",
    "        InputFieldMappingEntry(name=\"recordId\", source=\"/document/metadata_storage_name\")  \n",
    "    ],  \n",
    "    outputs=[OutputFieldMappingEntry(name=\"vector\", target_name=\"imageVector\")],  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to extract image vector\",  \n",
    "    skills=[skill],  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f' {skillset.name} created')  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagesearch-index created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"imageUrl\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(  \n",
    "        name=\"imageVector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=1024,  \n",
    "        vector_search_profile_name=\"myHnswProfile\",  \n",
    "    ),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            kind=VectorSearchAlgorithmKind.HNSW,  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=1000,  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "            ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ), \n",
    "    ],  \n",
    "   profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "# Create the search index with the vector search configuration  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer\n",
    "\n",
    "Create or update an indexer to process images and populate the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " imagesearch-index-indexer created\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to process images\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    field_mappings=[  \n",
    "        FieldMapping(source_field_name=\"metadata_storage_path\", target_field_name=\"imageUrl\"),  \n",
    "        FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")  \n",
    "    ],  \n",
    "    output_field_mappings=[  \n",
    "        FieldMapping(source_field_name=\"/document/imageVector\", target_field_name=\"imageVector\")  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector search by vectorizing your text query\n",
    "\n",
    "Perform a vector search to find the most relevant images based on the text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, aiVisionEndpoint, aiVisionApiKey):  \n",
    "    url = f\"{aiVisionEndpoint}/computervision/retrieval:vectorizeText\"  \n",
    "  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    }  \n",
    "  \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": aiVisionApiKey  \n",
    "    }  \n",
    "  \n",
    "    data = {  \n",
    "        \"text\": text  \n",
    "    }  \n",
    "  \n",
    "    response = requests.post(url, params=params, headers=headers, json=data)  \n",
    "  \n",
    "    if response.status_code == 200:  \n",
    "        embeddings = response.json()[\"vector\"]  \n",
    "        return embeddings  \n",
    "    else:  \n",
    "        print(f\"Error: {response.status_code} - {response.text}\")  \n",
    "        return None  \n",
    "\n",
    "  \n",
    "# Generate text embeddings for the query  \n",
    "query = \"winter clothes\"  \n",
    "  \n",
    "# Initialize the SearchClient  \n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query, aiVisionEndpoint, aiVisionApiKey), k_nearest_neighbors=3, fields=\"imageVector\")  \n",
    "\n",
    "# Perform vector search  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"imageUrl\"]  \n",
    ")   \n",
    "  \n",
    "# Print the search results  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Image URL: {result['imageUrl']}\") \n",
    "    display(Image(url=result['imageUrl'])) \n",
    "    print(\"\\n\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a vector search to find the most relevant images based on the image query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, aiVisionEndpoint, aiVisionApiKey):  \n",
    "    url = f\"{aiVisionEndpoint}/computervision/retrieval:vectorizeImage\"  \n",
    "  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    }  \n",
    "  \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": aiVisionApiKey  \n",
    "    }  \n",
    "  \n",
    "    data = {  \n",
    "        \"url\": text  \n",
    "    }  \n",
    "  \n",
    "    response = requests.post(url, params=params, headers=headers, json=data)  \n",
    "  \n",
    "    if response.status_code == 200:  \n",
    "        embeddings = response.json()[\"vector\"]  \n",
    "        return embeddings  \n",
    "    else:  \n",
    "        print(f\"Error: {response.status_code} - {response.text}\")  \n",
    "        return None  \n",
    "\n",
    "  \n",
    "# Generate text embeddings for the query (for context, this is a photo of a lady in a red hat)\n",
    "query = \"https://images.unsplash.com/photo-1593476087123-36d1de271f08?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=387&q=80\"  \n",
    "  \n",
    "# Initialize the SearchClient  \n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query, aiVisionEndpoint, aiVisionApiKey), k_nearest_neighbors=3, fields=\"imageVector\")  \n",
    "\n",
    "# Perform vector search  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"imageUrl\"]  \n",
    ")   \n",
    "  \n",
    "# Print the search results  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Image URL: {result['imageUrl']}\") \n",
    "    display(Image(url=result['imageUrl'])) \n",
    "    print(\"\\n\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
